{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import tsensor\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "names=\"统一编号\tX\tY\t地面高程\t井口高程\t地下水类型\t1990年1月\t1990年2月\t1990年3月\t1990年4月\t1990年5月\t1990年6月\t1990年7月\t1990年8月\t1990年9月\t1990年10月\t1990年11月\t1990年12月\t1991年1月\t1991年2月\t1991年3月\t1991年4月\t1991年5月\t1991年6月\t1991年7月\t1991年8月\t1991年9月\t1991年10月\t1991年11月\t1991年12月\t1992年1月\t1992年2月\t1992年3月\t1992年4月\t1992年5月\t1992年6月\t1992年7月\t1992年8月\t1992年9月\t1992年10月\t1992年11月\t1992年12月\t1993年1月\t1993年2月\t1993年3月\t1993年4月\t1993年5月\t1993年6月\t1993年7月\t1993年8月\t1993年9月\t1993年10月\t1993年11月\t1993年12月\t1994年1月\t1994年2月\t1994年3月\t1994年4月\t1994年5月\t1994年6月\t1994年7月\t1994年8月\t1994年9月\t1994年10月\t1994年11月\t1994年12月\t1995年1月\t1995年2月\t1995年3月\t1995年4月\t1995年5月\t1995年6月\t1995年7月\t1995年8月\t1995年9月\t1995年10月\t1995年11月\t1995年12月\t1996年1月\t1996年2月\t1996年3月\t1996年4月\t1996年5月\t1996年6月\t1996年7月\t1996年8月\t1996年9月\t1996年10月\t1996年11月\t1996年12月\t1997年1月\t1997年2月\t1997年3月\t1997年4月\t1997年5月\t1997年6月\t1997年7月\t1997年8月\t1997年9月\t1997年10月\t1997年11月\t1997年12月\t1998年1月\t1998年2月\t1998年3月\t1998年4月\t1998年5月\t1998年6月\t1998年7月\t1998年8月\t1998年9月\t1998年10月\t1998年11月\t1998年12月\t1999年1月\t1999年2月\t1999年3月\t1999年4月\t1999年5月\t1999年6月\t1999年7月\t1999年8月\t1999年9月\t1999年10月\t1999年11月\t1999年12月\t2000年1月\t2000年2月\t2000年3月\t2000年4月\t2000年5月\t2000年6月\t2000年7月\t2000年8月\t2000年9月\t2000年10月\t2000年11月\t2000年12月\t2001年1月\t2001年2月\t2001年3月\t2001年4月\t2001年5月\t2001年6月\t2001年7月\t2001年8月\t2001年9月\t2001年10月\t2001年11月\t2001年12月\t2002年1月\t2002年2月\t2002年3月\t2002年4月\t2002年5月\t2002年6月\t2002年7月\t2002年8月\t2002年9月\t2002年10月\t2002年11月\t2002年12月\t2003年1月\t2003年2月\t2003年3月\t2003年4月\t2003年5月\t2003年6月\t2003年7月\t2003年8月\t2003年9月\t2003年10月\t2003年11月\t2003年12月\t2004年1月\t2004年2月\t2004年3月\t2004年4月\t2004年5月\t2004年6月\t2004年7月\t2004年8月\t2004年9月\t2004年10月\t2004年11月\t2004年12月\t2005年1月\t2005年2月\t2005年3月\t2005年4月\t2005年5月\t2005年6月\t2005年7月\t2005年8月\t2005年9月\t2005年10月\t2005年11月\t2005年12月\t2006年1月\t2006年2月\t2006年3月\t2006年4月\t2006年5月\t2006年6月\t2006年7月\t2006年8月\t2006年9月\t2006年10月\t2006年11月\t2006年12月\t2007年1月\t2007年2月\t2007年3月\t2007年4月\t2007年5月\t2007年6月\t2007年7月\t2007年8月\t2007年9月\t2007年10月\t2007年11月\t2007年12月\t2008年1月\t2008年2月\t2008年3月\t2008年4月\t2008年5月\t2008年6月\t2008年7月\t2008年8月\t2008年9月\t2008年10月\t2008年11月\t2008年12月\t2009年1月\t2009年2月\t2009年3月\t2009年4月\t2009年5月\t2009年6月\t2009年7月\t2009年8月\t2009年9月\t2009年10月\t2009年11月\t2009年12月\t2010年1月\t2010年2月\t2010年3月\t2010年4月\t2010年5月\t2010年6月\t2010年7月\t2010年8月\t2010年9月\t2010年10月\t2010年11月\t2010年12月\t2011年1月\t2011年2月\t2011年3月\t2011年4月\t2011年5月\t2011年6月\t2011年7月\t2011年8月\t2011年9月\t2011年10月\t2011年11月\t2011年12月\t2012年1月\t2012年2月\t2012年3月\t2012年4月\t2012年5月\t2012年6月\t2012年7月\t2012年8月\t2012年9月\t2012年10月\t2012年11月\t2012年12月\t2013年1月\t2013年2月\t2013年3月\t2013年4月\t2013年5月\t2013年6月\t2013年7月\t2013年8月\t2013年9月\t2013年10月\t2013年11月\t2013年12月\t2014年1月\t2014年2月\t2014年3月\t2014年4月\t2014年5月\t2014年6月\t2014年7月\t2014年8月\t2014年9月\t2014年10月\t2014年11月\t2014年12月\t2015年1月\t2015年2月\t2015年3月\t2015年4月\t2015年5月\t2015年6月\t2015年7月\t2015年8月\t2015年9月\t2015年10月\t2015年11月\t2015年12月\t2016年1月\t2016年2月\t2016年3月\t2016年4月\t2016年5月\t2016年6月\t2016年7月\t2016年8月\t2016年9月\t2016年10月\t2016年11月\t2016年12月\t2017年1月\t2017年2月\t2017年3月\t2017年4月\t2017年5月\t2017年6月\t2017年7月\t2017年8月\t2017年9月\t2017年10月\t2017年11月\t2017年12月\t2018年1月\t2018年2月\t2018年3月\t2018年4月\t2018年5月\t2018年6月\t2018年7月\t2018年8月\t2018年9月\t2018年10月\t2018年11月\t2018年12月\"\n",
    "col_names=names.split()\n",
    "data=pd.read_excel('data.xlsx',names=col_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "data=data.iloc[:,6:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "    1990年1月  1990年2月  1990年3月  1990年4月  1990年5月  1990年6月  1990年7月  1990年8月  \\\n0   1095.59  1095.80  1093.78  1094.25  1094.65  1095.02  1095.42  1096.31   \n1   1103.76  1098.42  1098.06  1097.60  1098.91  1099.04  1100.09  1100.21   \n5   1107.13  1106.48  1106.23  1107.39  1107.13  1109.04  1107.26  1107.72   \n7   1119.58  1119.40  1119.40  1119.61  1119.76  1119.99  1119.85  1119.96   \n9   1122.31  1121.99  1121.99  1122.29  1122.43  1122.78  1122.87  1122.76   \n10  1122.09  1121.90  1121.89  1122.02  1121.94  1122.08  1122.11  1121.94   \n11  1106.69  1106.60  1106.53  1106.50  1106.44  1106.42  1106.39  1106.35   \n12  1090.34  1090.89  1090.02  1090.03  1089.84  1089.64  1088.93  1089.38   \n13  1098.18  1098.04  1097.37  1098.56  1097.65  1098.05  1097.81  1097.83   \n15  1105.86  1105.65  1105.49  1105.32  1105.23  1105.76  1105.81  1105.72   \n16  1128.71  1128.48  1128.60  1128.91  1129.18  1129.25  1129.27  1129.23   \n18  1123.78  1123.66  1123.72  1123.86  1123.88  1123.88  1123.80  1123.77   \n20  1116.44  1116.28  1116.39  1116.55  1116.39  1116.71  1116.64  1116.54   \n22  1119.22  1118.80  1118.87  1118.08  1119.11  1119.56  1119.55  1119.26   \n24  1096.78  1096.94  1096.65  1096.66  1096.64  1096.46  1096.40  1096.32   \n25  1114.73  1114.65  1114.64  1114.76  1114.76  1114.72  1114.68  1114.60   \n26  1102.63  1102.53  1102.48  1102.49  1102.46  1102.55  1102.50  1102.56   \n\n    1990年9月  1990年10月  ...  2018年3月  2018年4月  2018年5月    2018年6月   2018年7月  \\\n0   1096.03   1095.23  ...  1102.19  1097.18  1094.63  1092.3500  1091.370   \n1   1100.07   1099.28  ...  1102.91  1102.83  1102.92  1102.7400  1102.710   \n5   1107.97   1107.89  ...  1112.29  1109.89  1109.29  1109.2800  1108.590   \n7   1119.94   1119.64  ...  1119.27  1119.05  1119.08  1119.1500  1119.050   \n9   1122.63   1122.35  ...  1121.07  1121.23  1121.37  1121.7700  1121.090   \n10  1121.78   1121.68  ...  1121.00  1121.10  1121.50  1121.3800  1121.000   \n11  1106.51   1106.54  ...  1102.05  1099.85  1098.63  1097.6500  1097.750   \n12  1091.03   1090.03  ...  1098.74  1096.24  1095.64  1094.9400  1094.640   \n13  1098.77   1098.65  ...  1099.63  1098.63  1097.83  1097.3300  1094.630   \n15  1105.86   1105.99  ...  1102.17  1101.53  1100.67  1099.8700  1100.020   \n16  1129.24   1127.90  ...  1128.51  1129.06  1129.26  1129.3600  1129.060   \n18  1123.86   1123.81  ...  1123.91  1123.98  1124.38  1124.4800  1124.210   \n20  1116.72   1116.61  ...  1115.77  1115.87  1115.87  1115.7700  1115.720   \n22  1119.23   1118.95  ...  1120.23  1119.72  1119.83  1119.7300  1119.600   \n24  1096.78   1096.77  ...  1093.74  1091.79  1090.94  1089.9400  1089.670   \n25  1114.56   1114.53  ...  1112.39  1112.13  1111.87  1112.0925  1112.315   \n26  1102.61   1101.57  ...  1092.97  1092.68  1092.07  1091.0600  1090.820   \n\n      2018年8月  2018年9月  2018年10月  2018年11月  2018年12月  \n0   1091.5900  1091.76   1096.96   1098.15   1098.15  \n1   1103.0200  1103.38   1103.57   1103.45   1103.45  \n5   1103.3900  1106.56   1101.74   1102.69   1102.69  \n7   1119.4300  1119.95   1119.96   1119.95   1119.95  \n9   1121.4200  1121.62   1121.24   1121.30   1121.30  \n10  1120.8700  1121.10   1121.27   1121.30   1121.30  \n11  1097.4800  1098.45   1098.65   1098.86   1098.86  \n12  1094.5700  1096.54   1096.42   1097.04   1097.04  \n13  1094.7800  1096.26   1096.33   1096.23   1096.23  \n15  1100.0900  1100.83   1101.36   1101.47   1101.47  \n16  1128.9500  1128.79   1128.63   1128.53   1128.53  \n18  1124.1100  1124.00   1123.88   1124.49   1124.49  \n20  1115.6900  1116.01   1116.01   1115.76   1115.76  \n22  1119.7300  1120.65   1119.70   1119.33   1119.33  \n24  1089.8300  1091.87   1090.93   1091.34   1091.34  \n25  1112.5375  1112.76   1112.68   1112.59   1112.59  \n26  1090.9700  1091.27   1091.14   1091.45   1091.45  \n\n[17 rows x 348 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1990年1月</th>\n      <th>1990年2月</th>\n      <th>1990年3月</th>\n      <th>1990年4月</th>\n      <th>1990年5月</th>\n      <th>1990年6月</th>\n      <th>1990年7月</th>\n      <th>1990年8月</th>\n      <th>1990年9月</th>\n      <th>1990年10月</th>\n      <th>...</th>\n      <th>2018年3月</th>\n      <th>2018年4月</th>\n      <th>2018年5月</th>\n      <th>2018年6月</th>\n      <th>2018年7月</th>\n      <th>2018年8月</th>\n      <th>2018年9月</th>\n      <th>2018年10月</th>\n      <th>2018年11月</th>\n      <th>2018年12月</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1095.59</td>\n      <td>1095.80</td>\n      <td>1093.78</td>\n      <td>1094.25</td>\n      <td>1094.65</td>\n      <td>1095.02</td>\n      <td>1095.42</td>\n      <td>1096.31</td>\n      <td>1096.03</td>\n      <td>1095.23</td>\n      <td>...</td>\n      <td>1102.19</td>\n      <td>1097.18</td>\n      <td>1094.63</td>\n      <td>1092.3500</td>\n      <td>1091.370</td>\n      <td>1091.5900</td>\n      <td>1091.76</td>\n      <td>1096.96</td>\n      <td>1098.15</td>\n      <td>1098.15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1103.76</td>\n      <td>1098.42</td>\n      <td>1098.06</td>\n      <td>1097.60</td>\n      <td>1098.91</td>\n      <td>1099.04</td>\n      <td>1100.09</td>\n      <td>1100.21</td>\n      <td>1100.07</td>\n      <td>1099.28</td>\n      <td>...</td>\n      <td>1102.91</td>\n      <td>1102.83</td>\n      <td>1102.92</td>\n      <td>1102.7400</td>\n      <td>1102.710</td>\n      <td>1103.0200</td>\n      <td>1103.38</td>\n      <td>1103.57</td>\n      <td>1103.45</td>\n      <td>1103.45</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1107.13</td>\n      <td>1106.48</td>\n      <td>1106.23</td>\n      <td>1107.39</td>\n      <td>1107.13</td>\n      <td>1109.04</td>\n      <td>1107.26</td>\n      <td>1107.72</td>\n      <td>1107.97</td>\n      <td>1107.89</td>\n      <td>...</td>\n      <td>1112.29</td>\n      <td>1109.89</td>\n      <td>1109.29</td>\n      <td>1109.2800</td>\n      <td>1108.590</td>\n      <td>1103.3900</td>\n      <td>1106.56</td>\n      <td>1101.74</td>\n      <td>1102.69</td>\n      <td>1102.69</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1119.58</td>\n      <td>1119.40</td>\n      <td>1119.40</td>\n      <td>1119.61</td>\n      <td>1119.76</td>\n      <td>1119.99</td>\n      <td>1119.85</td>\n      <td>1119.96</td>\n      <td>1119.94</td>\n      <td>1119.64</td>\n      <td>...</td>\n      <td>1119.27</td>\n      <td>1119.05</td>\n      <td>1119.08</td>\n      <td>1119.1500</td>\n      <td>1119.050</td>\n      <td>1119.4300</td>\n      <td>1119.95</td>\n      <td>1119.96</td>\n      <td>1119.95</td>\n      <td>1119.95</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1122.31</td>\n      <td>1121.99</td>\n      <td>1121.99</td>\n      <td>1122.29</td>\n      <td>1122.43</td>\n      <td>1122.78</td>\n      <td>1122.87</td>\n      <td>1122.76</td>\n      <td>1122.63</td>\n      <td>1122.35</td>\n      <td>...</td>\n      <td>1121.07</td>\n      <td>1121.23</td>\n      <td>1121.37</td>\n      <td>1121.7700</td>\n      <td>1121.090</td>\n      <td>1121.4200</td>\n      <td>1121.62</td>\n      <td>1121.24</td>\n      <td>1121.30</td>\n      <td>1121.30</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1122.09</td>\n      <td>1121.90</td>\n      <td>1121.89</td>\n      <td>1122.02</td>\n      <td>1121.94</td>\n      <td>1122.08</td>\n      <td>1122.11</td>\n      <td>1121.94</td>\n      <td>1121.78</td>\n      <td>1121.68</td>\n      <td>...</td>\n      <td>1121.00</td>\n      <td>1121.10</td>\n      <td>1121.50</td>\n      <td>1121.3800</td>\n      <td>1121.000</td>\n      <td>1120.8700</td>\n      <td>1121.10</td>\n      <td>1121.27</td>\n      <td>1121.30</td>\n      <td>1121.30</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1106.69</td>\n      <td>1106.60</td>\n      <td>1106.53</td>\n      <td>1106.50</td>\n      <td>1106.44</td>\n      <td>1106.42</td>\n      <td>1106.39</td>\n      <td>1106.35</td>\n      <td>1106.51</td>\n      <td>1106.54</td>\n      <td>...</td>\n      <td>1102.05</td>\n      <td>1099.85</td>\n      <td>1098.63</td>\n      <td>1097.6500</td>\n      <td>1097.750</td>\n      <td>1097.4800</td>\n      <td>1098.45</td>\n      <td>1098.65</td>\n      <td>1098.86</td>\n      <td>1098.86</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1090.34</td>\n      <td>1090.89</td>\n      <td>1090.02</td>\n      <td>1090.03</td>\n      <td>1089.84</td>\n      <td>1089.64</td>\n      <td>1088.93</td>\n      <td>1089.38</td>\n      <td>1091.03</td>\n      <td>1090.03</td>\n      <td>...</td>\n      <td>1098.74</td>\n      <td>1096.24</td>\n      <td>1095.64</td>\n      <td>1094.9400</td>\n      <td>1094.640</td>\n      <td>1094.5700</td>\n      <td>1096.54</td>\n      <td>1096.42</td>\n      <td>1097.04</td>\n      <td>1097.04</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1098.18</td>\n      <td>1098.04</td>\n      <td>1097.37</td>\n      <td>1098.56</td>\n      <td>1097.65</td>\n      <td>1098.05</td>\n      <td>1097.81</td>\n      <td>1097.83</td>\n      <td>1098.77</td>\n      <td>1098.65</td>\n      <td>...</td>\n      <td>1099.63</td>\n      <td>1098.63</td>\n      <td>1097.83</td>\n      <td>1097.3300</td>\n      <td>1094.630</td>\n      <td>1094.7800</td>\n      <td>1096.26</td>\n      <td>1096.33</td>\n      <td>1096.23</td>\n      <td>1096.23</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1105.86</td>\n      <td>1105.65</td>\n      <td>1105.49</td>\n      <td>1105.32</td>\n      <td>1105.23</td>\n      <td>1105.76</td>\n      <td>1105.81</td>\n      <td>1105.72</td>\n      <td>1105.86</td>\n      <td>1105.99</td>\n      <td>...</td>\n      <td>1102.17</td>\n      <td>1101.53</td>\n      <td>1100.67</td>\n      <td>1099.8700</td>\n      <td>1100.020</td>\n      <td>1100.0900</td>\n      <td>1100.83</td>\n      <td>1101.36</td>\n      <td>1101.47</td>\n      <td>1101.47</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1128.71</td>\n      <td>1128.48</td>\n      <td>1128.60</td>\n      <td>1128.91</td>\n      <td>1129.18</td>\n      <td>1129.25</td>\n      <td>1129.27</td>\n      <td>1129.23</td>\n      <td>1129.24</td>\n      <td>1127.90</td>\n      <td>...</td>\n      <td>1128.51</td>\n      <td>1129.06</td>\n      <td>1129.26</td>\n      <td>1129.3600</td>\n      <td>1129.060</td>\n      <td>1128.9500</td>\n      <td>1128.79</td>\n      <td>1128.63</td>\n      <td>1128.53</td>\n      <td>1128.53</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1123.78</td>\n      <td>1123.66</td>\n      <td>1123.72</td>\n      <td>1123.86</td>\n      <td>1123.88</td>\n      <td>1123.88</td>\n      <td>1123.80</td>\n      <td>1123.77</td>\n      <td>1123.86</td>\n      <td>1123.81</td>\n      <td>...</td>\n      <td>1123.91</td>\n      <td>1123.98</td>\n      <td>1124.38</td>\n      <td>1124.4800</td>\n      <td>1124.210</td>\n      <td>1124.1100</td>\n      <td>1124.00</td>\n      <td>1123.88</td>\n      <td>1124.49</td>\n      <td>1124.49</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1116.44</td>\n      <td>1116.28</td>\n      <td>1116.39</td>\n      <td>1116.55</td>\n      <td>1116.39</td>\n      <td>1116.71</td>\n      <td>1116.64</td>\n      <td>1116.54</td>\n      <td>1116.72</td>\n      <td>1116.61</td>\n      <td>...</td>\n      <td>1115.77</td>\n      <td>1115.87</td>\n      <td>1115.87</td>\n      <td>1115.7700</td>\n      <td>1115.720</td>\n      <td>1115.6900</td>\n      <td>1116.01</td>\n      <td>1116.01</td>\n      <td>1115.76</td>\n      <td>1115.76</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1119.22</td>\n      <td>1118.80</td>\n      <td>1118.87</td>\n      <td>1118.08</td>\n      <td>1119.11</td>\n      <td>1119.56</td>\n      <td>1119.55</td>\n      <td>1119.26</td>\n      <td>1119.23</td>\n      <td>1118.95</td>\n      <td>...</td>\n      <td>1120.23</td>\n      <td>1119.72</td>\n      <td>1119.83</td>\n      <td>1119.7300</td>\n      <td>1119.600</td>\n      <td>1119.7300</td>\n      <td>1120.65</td>\n      <td>1119.70</td>\n      <td>1119.33</td>\n      <td>1119.33</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>1096.78</td>\n      <td>1096.94</td>\n      <td>1096.65</td>\n      <td>1096.66</td>\n      <td>1096.64</td>\n      <td>1096.46</td>\n      <td>1096.40</td>\n      <td>1096.32</td>\n      <td>1096.78</td>\n      <td>1096.77</td>\n      <td>...</td>\n      <td>1093.74</td>\n      <td>1091.79</td>\n      <td>1090.94</td>\n      <td>1089.9400</td>\n      <td>1089.670</td>\n      <td>1089.8300</td>\n      <td>1091.87</td>\n      <td>1090.93</td>\n      <td>1091.34</td>\n      <td>1091.34</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1114.73</td>\n      <td>1114.65</td>\n      <td>1114.64</td>\n      <td>1114.76</td>\n      <td>1114.76</td>\n      <td>1114.72</td>\n      <td>1114.68</td>\n      <td>1114.60</td>\n      <td>1114.56</td>\n      <td>1114.53</td>\n      <td>...</td>\n      <td>1112.39</td>\n      <td>1112.13</td>\n      <td>1111.87</td>\n      <td>1112.0925</td>\n      <td>1112.315</td>\n      <td>1112.5375</td>\n      <td>1112.76</td>\n      <td>1112.68</td>\n      <td>1112.59</td>\n      <td>1112.59</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>1102.63</td>\n      <td>1102.53</td>\n      <td>1102.48</td>\n      <td>1102.49</td>\n      <td>1102.46</td>\n      <td>1102.55</td>\n      <td>1102.50</td>\n      <td>1102.56</td>\n      <td>1102.61</td>\n      <td>1101.57</td>\n      <td>...</td>\n      <td>1092.97</td>\n      <td>1092.68</td>\n      <td>1092.07</td>\n      <td>1091.0600</td>\n      <td>1090.820</td>\n      <td>1090.9700</td>\n      <td>1091.27</td>\n      <td>1091.14</td>\n      <td>1091.45</td>\n      <td>1091.45</td>\n    </tr>\n  </tbody>\n</table>\n<p>17 rows × 348 columns</p>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.dropna(thresh=12*28).interpolate(axis=1)\n",
    "data.fillna(method=\"ffill\",axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 只要每个月地下水位高度数据\n",
    "data=data.iloc[0:1,6:353]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   1990年1月  1990年2月  1990年3月  1990年4月  1990年5月  1990年6月  1990年7月  1990年8月  \\\n0  1095.59   1095.8  1093.78  1094.25  1094.65  1095.02  1095.42  1096.31   \n\n   1990年9月  1990年10月  ...  2018年2月  2018年3月  2018年4月  2018年5月  2018年6月  \\\n0  1096.03   1095.23  ...  1094.39  1102.19  1097.18  1094.63  1092.35   \n\n   2018年7月  2018年8月  2018年9月  2018年10月  2018年11月  \n0  1091.37  1091.59  1091.76   1096.96   1098.15  \n\n[1 rows x 347 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1990年1月</th>\n      <th>1990年2月</th>\n      <th>1990年3月</th>\n      <th>1990年4月</th>\n      <th>1990年5月</th>\n      <th>1990年6月</th>\n      <th>1990年7月</th>\n      <th>1990年8月</th>\n      <th>1990年9月</th>\n      <th>1990年10月</th>\n      <th>...</th>\n      <th>2018年2月</th>\n      <th>2018年3月</th>\n      <th>2018年4月</th>\n      <th>2018年5月</th>\n      <th>2018年6月</th>\n      <th>2018年7月</th>\n      <th>2018年8月</th>\n      <th>2018年9月</th>\n      <th>2018年10月</th>\n      <th>2018年11月</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1095.59</td>\n      <td>1095.8</td>\n      <td>1093.78</td>\n      <td>1094.25</td>\n      <td>1094.65</td>\n      <td>1095.02</td>\n      <td>1095.42</td>\n      <td>1096.31</td>\n      <td>1096.03</td>\n      <td>1095.23</td>\n      <td>...</td>\n      <td>1094.39</td>\n      <td>1102.19</td>\n      <td>1097.18</td>\n      <td>1094.63</td>\n      <td>1092.35</td>\n      <td>1091.37</td>\n      <td>1091.59</td>\n      <td>1091.76</td>\n      <td>1096.96</td>\n      <td>1098.15</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 347 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 行归一化\n",
    "data_norm=data.sub(data.min(axis=1),axis=0).divide((data.max(axis=1)-data.min(axis=1)),axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "m,n=data_norm.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 整理成有监督数据集\n",
    "data_x,data_y=[],[]\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        if j+13>n:\n",
    "            break\n",
    "        temp=data_norm.iloc[i,j:j+13]\n",
    "        if temp.isna().sum()>0:\n",
    "            continue\n",
    "        data_x.append(temp[:-1].values)\n",
    "        data_y.append(temp[-1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n"
     ]
    }
   ],
   "source": [
    "# 数据集包含9202个样本\n",
    "print(len(data_x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# 划分数据集（训练集0.7，测试集0.3）\n",
    "split_rate=0.7\n",
    "train_len=int(len(data_x)*split_rate)\n",
    "train_x,train_y=torch.tensor(data_x[:train_len],dtype=torch.float),\\\n",
    "                torch.tensor(data_y[:train_len],dtype=torch.float)\n",
    "test_x,test_y=torch.tensor(data_x[train_len:],dtype=torch.float),\\\n",
    "              torch.tensor(data_y[train_len:],dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "97"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([225, 12, 1]) torch.Size([97, 12, 1])\n"
     ]
    }
   ],
   "source": [
    "train_x=train_x.reshape(train_x.shape[0],train_x.shape[1],-1)\n",
    "test_x=test_x.reshape(test_x.shape[0],test_x.shape[1],-1)\n",
    "print(train_x.shape,test_x.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "# 定义网络模型\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,input_size=1,hidden_size=16,num_layers=2,output_size=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm=nn.LSTM(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers)\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "        self.fc=nn.Linear(hidden_size,output_size)\n",
    "    def forward(self,x):\n",
    "        with tsensor.clarify():\n",
    "            out,_=self.lstm(x)\n",
    "            s,b,h=out.shape\n",
    "            # print(out.shape)\n",
    "            out=out.view(s*b,-1)\n",
    "            out=self.dropout(out)\n",
    "            out=self.fc(out)\n",
    "        return out.view(s,b)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "# 超参数\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lr = 0.01\n",
    "batch_size = 1\n",
    "num_epochs = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "train_dataset=torch.utils.data.TensorDataset(train_x,train_y)\n",
    "train_dataloader=torch.utils.data.DataLoader(train_dataset,batch_size=batch_size)\n",
    "test_dataset=torch.utils.data.TensorDataset(test_x,test_y)\n",
    "test_dataloader=torch.utils.data.DataLoader(test_dataset,batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 1]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for X,y in train_dataloader:\n",
    "    print(X.shape,y.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "# 创建网络\n",
    "net=LSTM().to(device)\n",
    "# 损失函数 L2 Loss\n",
    "criterion = nn.MSELoss()\n",
    "# 优化器\n",
    "optimizer = torch.optim.SGD(params=net.parameters(), lr=lr,momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:432: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([2, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor(9.)"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=torch.tensor([1.,2.,3.])\n",
    "q_hat=torch.tensor([[4,5,6],[4.,5.,6.]])\n",
    "# q_hat=q_hat.unsqueeze(dim=2)\n",
    "print(q.shape)\n",
    "print(q_hat.shape)\n",
    "criterion(q_hat.squeeze(),q)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "# 测试评估\n",
    "def evaluate_test_loss(net,device):\n",
    "    loss_sum = 0\n",
    "    batch = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X=X.reshape(X.shape[1],X.shape[0],-1)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            loss_sum += (y_hat-y).abs().sum()\n",
    "            batch += 1\n",
    "        test_loss = loss_sum / (batch * batch_size)\n",
    "    return test_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "# 训练\n",
    "def train(device):\n",
    "    print('training on', device)\n",
    "    for epoch in range(num_epochs + 1):\n",
    "        train_l_sum, batch_count = 0.0, 0\n",
    "        net.train()\n",
    "        for X, y in train_dataloader:\n",
    "            X=X.reshape(X.shape[1],X.shape[0],-1)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # print(X.shape,y.shape)\n",
    "            # print('y', y)\n",
    "            y_hat = net(X)\n",
    "            # print('y_hat', y_hat.shape)\n",
    "            # print('y', y.shape)\n",
    "            l = criterion(y_hat.squeeze(), y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_l_sum += l.item()\n",
    "            batch_count += 1\n",
    "        if epoch % 5 == 0:\n",
    "            test_loss = 1\n",
    "            print('epoch %d,train_loss %.4f,test_loss %.4f' % (epoch, train_l_sum / batch_count,test_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "epoch 0,train_loss 0.0079,test_loss 1.0000\n",
      "epoch 5,train_loss 0.0102,test_loss 1.0000\n",
      "epoch 10,train_loss 0.0102,test_loss 1.0000\n",
      "epoch 15,train_loss 0.0102,test_loss 1.0000\n",
      "epoch 20,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 25,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 30,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 35,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 40,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 45,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 50,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 55,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 60,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 65,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 70,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 75,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 80,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 85,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 90,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 95,train_loss 0.0103,test_loss 1.0000\n",
      "epoch 100,train_loss 0.0103,test_loss 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:432: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "train(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3967093235831715, 0.415904936014619, 0.23126142595977697, 0.2742230347349164, 0.3107861060329135, 0.3446069469835432, 0.3811700182815404, 0.46252285191955395, 0.43692870201096423, 0.36380255941499073, 0.3263254113345447, 0.37568555758682626, 4.706883430480957, 5.197386741638184, 5.398294925689697, 6.9037065505981445, 7.666369438171387, 8.811790466308594, 8.954126358032227, 10.393819808959961, 11.84153938293457, 12.567767143249512, 14.288421630859375, 14.117076873779297, 15.896319389343262, 16.060626983642578, 14.63040542602539, 13.795592308044434, 15.104358673095703, 14.532527923583984, 13.179469108581543, 13.622109413146973, 14.273534774780273, 14.001789093017578, 14.995460510253906, 14.211600303649902, 14.689910888671875, 15.046283721923828, 13.446325302124023, 15.045236587524414, 14.818958282470703, 15.353248596191406, 12.7340087890625, 13.768640518188477, 15.13640022277832, 14.720361709594727, 12.438197135925293, 12.902565002441406, 13.829598426818848, 15.624162673950195]\n"
     ]
    }
   ],
   "source": [
    "predict_res=[]\n",
    "valid=data.iloc[0]\n",
    "valid_data=data.iloc[0,:12]\n",
    "# predict_res=valid_data.values.tolist()\n",
    "# 归一化\n",
    "norm_min=valid.min()\n",
    "norm_max=valid.max()\n",
    "valid_data=(valid_data-norm_min)/(norm_max-norm_min)\n",
    "predict_res=valid_data.values.tolist()\n",
    "valid_data_tensor=torch.tensor(valid_data.values,dtype=torch.float).to(device)\n",
    "for _ in range(50-12):\n",
    "    # print(valid_data_tensor)\n",
    "    predict=net(valid_data_tensor.unsqueeze(1).unsqueeze(2)).sum()\n",
    "    # 反归一化\n",
    "    # predict_value=(predict*(norm_max-norm_min)+norm_min).item()\n",
    "    predict_value=predict.item()\n",
    "    predict_res.append(predict_value)\n",
    "    valid_data_tensor=torch.cat((valid_data_tensor[1:],predict.squeeze().unsqueeze(dim=0)),dim=0)\n",
    "\n",
    "print(predict_res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.3967093235831715,\n 0.415904936014619,\n 0.23126142595977697,\n 0.2742230347349164,\n 0.3107861060329135,\n 0.3446069469835432,\n 0.3811700182815404,\n 0.46252285191955395,\n 0.43692870201096423,\n 0.36380255941499073,\n 0.3263254113345447,\n 0.37568555758682626,\n 4.706883430480957,\n 5.197386741638184,\n 5.398294925689697,\n 6.9037065505981445,\n 7.666369438171387,\n 8.811790466308594,\n 8.954126358032227,\n 10.393819808959961,\n 11.84153938293457,\n 12.567767143249512,\n 14.288421630859375,\n 14.117076873779297,\n 15.896319389343262,\n 16.060626983642578,\n 14.63040542602539,\n 13.795592308044434,\n 15.104358673095703,\n 14.532527923583984,\n 13.179469108581543,\n 13.622109413146973,\n 14.273534774780273,\n 14.001789093017578,\n 14.995460510253906,\n 14.211600303649902,\n 14.689910888671875,\n 15.046283721923828,\n 13.446325302124023,\n 15.045236587524414,\n 14.818958282470703,\n 15.353248596191406,\n 12.7340087890625,\n 13.768640518188477,\n 15.13640022277832,\n 14.720361709594727,\n 12.438197135925293,\n 12.902565002441406,\n 13.829598426818848,\n 15.624162673950195]"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39670932 0.41590494 0.23126143 0.27422303 0.31078611 0.34460695\n",
      " 0.38117002 0.46252285 0.4369287  0.36380256 0.32632541 0.37568556\n",
      " 0.28153565 0.21480804 0.21206581 0.20292505 0.22303473 0.28610603\n",
      " 0.32541133 0.36106033 0.35740402 0.34095064 0.20109689 0.32358318\n",
      " 0.25959781 0.3464351  0.1809872  0.15813528 0.16087751 0.22120658\n",
      " 0.28610603 0.31444241 0.30621572 0.35648995 0.3583181  0.40036563\n",
      " 0.37202925 0.34552102 0.40767824 0.3308958  0.37294333 0.24588665\n",
      " 0.34095064 0.35100548 0.36837294 0.50274223 0.36288848 0.3820841\n",
      " 0.33180987 0.27605119 0.24314442 0.26508227 0.2714808  0.32723949\n",
      " 0.37477148 0.32632541 0.39488117 0.42321755 0.23400366 0.32358318\n",
      " 0.24588665 0.14533821 0.15813528 0.17184644 0.17550274 0.24497258\n",
      " 0.2714808  0.36197441 0.4250457  0.36837294 0.34095064 0.35374771\n",
      " 0.27696527 0.22303473 0.18738574 0.19469835 0.26965265 0.35557587\n",
      " 0.40585009 0.33546618 0.34552102 0.34826325 0.21755027 0.26325411\n",
      " 0.28702011 0.19561243 0.1809872  0.08500914 0.06489945 0.14533821\n",
      " 0.17367459 0.20292505 0.19926874 0.20840951 0.18007313 0.19835466\n",
      " 0.21572212 0.22486289 0.17276051 0.1179159  0.13528336 0.22120658\n",
      " 0.24680073 0.24497258 0.31078611 0.29250457 0.2202925  0.26234004\n",
      " 0.23491773 0.23583181 0.26051188 0.20749543 0.21389397 0.27330896\n",
      " 0.30255941 0.31992687 0.3071298  0.32723949 0.27513711 0.29341865\n",
      " 0.28427788 0.28702011 0.25776965 0.23034735 0.2440585  0.30895795\n",
      " 0.36014625 0.32175503 0.39031079 0.45338208 0.40402194 0.45338208\n",
      " 0.46435101 0.55667276 0.50365631 0.39031079 0.39396709 0.42413163\n",
      " 0.44241316 0.45063985 0.48080439 0.51919561 0.48994516 0.51919561\n",
      " 0.52925046 0.55301645 0.55027422 0.49634369 0.476234   0.51736746\n",
      " 0.56032907 0.55484461 0.55941499 0.7321755  0.64990859 0.61608775\n",
      " 0.59323583 0.59232176 0.62248629 0.60968921 0.59232176 0.5904936\n",
      " 0.60054845 0.59414991 0.7321755  0.78244973 0.68555759 0.63254113\n",
      " 0.62888483 0.70201097 0.66819013 0.64716636 0.71846435 0.68647166\n",
      " 0.67550274 0.69195612 0.73674589 0.78153565 0.8308958  0.82541133\n",
      " 0.8226691  0.71480804 0.76234004 0.68372943 0.68190128 0.64076782\n",
      " 0.57769653 0.60877514 0.68281536 0.76234004 0.76234004 0.70566728\n",
      "        nan 0.76142596 0.78519196 0.66270567 0.66636197 0.65173675\n",
      " 0.64808044 0.74314442 0.71389397 0.75776965 0.64076782 0.68738574\n",
      " 0.76599634 0.80164534 0.8583181  0.76508227 0.73765996 0.71572212\n",
      " 0.73857404 0.65722121 0.67184644 0.71023766 0.74223035 0.71023766\n",
      " 0.77422303 0.85100548 0.80164534 0.68464351 0.68647166 0.5749543\n",
      " 0.48720293 0.60146252 0.63071298 0.73034735 0.69104205 0.61882998\n",
      " 0.73674589 0.75045704 0.77605119 0.77422303 0.74040219 0.6928702\n",
      " 0.55758684 0.51462523 0.59140768 0.62157221 0.65082267 0.6535649\n",
      " 0.65813528 0.60877514 0.59140768 0.57769653 0.60146252 0.58409506\n",
      " 0.53290676 0.52285192 0.56855576 0.62431444 0.65630713 0.62797075\n",
      " 0.70383912 0.69469835 0.71023766 0.68829982 0.70932358 0.4095064\n",
      " 0.3308958  0.23857404 0.31992687 0.31352834 0.31352834 0.30347349\n",
      " 0.30804388 0.32815356 0.34369287 0.33180987 0.32449726 0.24862888\n",
      " 0.19744059 0.17641682 0.29341865 0.31078611 0.26599634 0.21389397\n",
      " 0.24040219 0.25137112 0.28062157 0.28427788 0.26051188 0.18281536\n",
      " 0.12340037 0.07678245 0.04204753 0.0786106  0.09872029 0.1261426\n",
      " 0.25502742 0.21115174 0.26965265 0.24223035 0.19835466 0.13528336\n",
      " 0.08043876 0.03382084 0.         0.01279707 0.03290676 0.02925046\n",
      " 0.08775137 0.2166362  0.17276051 0.20383912 0.20383912 0.16727605\n",
      " 0.0904936  0.06581353 0.0511883  0.08866545 0.15722121 0.18647166\n",
      " 0.2166362  0.2202925  0.26142596 0.26965265 0.26873857 0.26051188\n",
      " 0.20109689 0.14442413 0.1261426  0.14442413 0.23400366 0.20109689\n",
      " 0.2321755  0.26691042 0.28062157 0.27787934 0.27239488 0.21389397\n",
      " 0.16636197 0.12340037 0.13893967 0.14259598 0.17458867 0.1773309\n",
      " 0.2202925  0.28702011 1.         0.54204753 0.30895795 0.10054845\n",
      " 0.01096892 0.03107861 0.04661792 0.52193784 0.63071298]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x2963d2ba850>]"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 24180 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "D:\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 26376 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "D:\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 24180 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "D:\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 26376 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd5hcxZXof9WTs2akURwJBRSMhEQYEU0OJhljjA3YxoCx8bIO2Ot1en5v7XVa7zqsvfZiIwMG2wTbgIkGBCJjSTCSECihHEZpRjOaHLu73h+nrvqqNaPp6e6Znuk5v+/rr7vrhjq37qlT556qW2WstSiKoijpRSDVAiiKoijJR427oihKGqLGXVEUJQ1R464oipKGqHFXFEVJQzIHM7MxY8bYqVOnDmaWiqIow54VK1YcsNaW9+eYQTXuU6dOpaqqajCzVBRFGfYYY3b09xgNyyiKoqQhatwVRVHSEDXuiqIoaYgad0VRlDREjbuiKEoaosZdURQlDenTuBtj7jHG1Bhj1kSlf9EY854xZq0x5r8GTkRFURSlv8Tiud8LXOJPMMacB3wImG+tnQv8NPmiKcogEw7DjqXw5u8g1J1qaRQlIfp8icla+6oxZmpU8m3Aj621nW6fmuSLpiiDQDgEO5fCusdh3RPQsk/S88tg3kdSK5uiJEC8MfdZwFnGmOXGmFeMMQt729EYc6sxpsoYU1VbWxtndoqSZFpq4amvwM9mw72Xw8o/wOSFcPVdUDQB3n0k1RIqSkLEO/1AJlAKnAYsBP5ijJlue1jWyVq7CFgEUFlZqcs+KUODl34Iq/4Ic66AuVfBsRdBTqFs2/s2LL8T2g9CXmlq5VSUOInXc68GHrXCm0AYGJM8sRRlALEWNr8Asy6Bj90Hcz8cMewg4ZhwN6x/MnUyKkqCxGvcHwPOBzDGzAKygQPJEkpRBpQDm6BxFxx7Qc/bJ54IZTPg3b8OrlxKehIOQ8POQc82lqGQDwJLgdnGmGpjzC3APcB0NzzyIeDGnkIyijIk2fyCfM/oxbgbA8dfA9teg+Z9gyeXkp7sfRt+cbx02A8isYyWub6XTZ9MsiyKMjhsfgHGzILSY3rfZ9418Mp/wppH4fR/HjzZlPRjyxL5nnL6oGarb6gqI4vudtjxBhx74dH3K58F4+fDmocHRy4lfdn8IkxYAIX9WmsjYdS4KyOL7W9AsKP3eLuf46+B3SugfuvAy6UcSSgIz/9bJIw2HOlohOo3ew8BDiBq3JWRxeYXIDMXjjmz7329l5h0zPvgEw7Dk1+CN34Jb92damniZ9urEA7G5kwkGTXuyshi8wsw9f2Qldf3viUVMOUMGTWj4wUGD2th8bfh7fshrwz2vpNqieJn8xLILoKKUwY9azXuysjh4Hao29R3vN3P8dfAgfdg/5q+941m+xuw6v7+HzfSeeW/YNkdcNo/w/u/DE3V0Faf2Dn3rIKfzoIV9yVHxliwVjpTp50NmdmDl69DjbsyctjsRi30x7gfdxUEMuHdfnasWgtPfAEe/2d4667+HTuQWJucMdfN++EvN8KLP4j9mH1r4M5z4LWfy9u/PbHsN/Dyj+CET8DFP5RObYC9qxOTt+oeaNkvoZ5nvyVzCg00dZulrI89f+Dz6gE17srIYfMSGDUFRh8b+zEFo2HG+bDmEYkDx8rOpdIRW1wBf/8avPds/+UdCF77qYy53vpy/Od471n4zRmw7jFYegd0d8R23Mo/iJFe8u/w87nwzDfh4I7I9rcfgGe/Ce/7IHzwfyAQiBj3fQmEZrrbYe1jMP9aOPU2eSp44GPS2TmQeM5ECjpTQY27MlIIdsG2V8RrN6Z/x867Rt5orX4z9mNW3Q/ZhXDry2KgHr4Zdq/sX77Jpr0B3viV/H7yy2L0+kN3Ozz9r/DgtTK52gf+A7pbpVz7wlrY8DTMvgz+6XUx4G/9Dv7nBPjrzdJIPP4FmH4ufORuyHCv4BSMhuJJicXd3/s7dDbJ08ClP4YrfiGN210XDexIqC1L5E3nsmkDl8dRUOOujAx2LYeulv6FZDzmXCYjbGKdjqCzGdb+DeZdLWObP/4XyB8DD1x7uKc62Cz7DXQ2wgd+BAe3wcs/jv3Yfe/ConPFIJ/+BfjsElh4i3QWbniq7+P3rpbY+ZzLYfzxcPWdcPs7cMYXpZP7uW/BpJPg2vshM+fwY8fPl/zjZfWfpYGYepb8r7wZbngMWmvgd+fLm8jJprsDtr+eklEyHmrclZHB5hckdu5V8P6QUwSzL5VH+1gW8Vj7mHi0J94g/4vGwScfhlAn3H9N7/HmgaS9QYz7nCvg9M+LbP/4Vd+xbGth2W/FCLY3wA1/gw/8UAxwZg7MvAjee6bvGPaGp8EEZLI2j5JJcNH34CtrxVv/xMOHT+DmMWG+dIR3tfX/ultq5N7P/5iEeTymnQWfWQIF5fDHq5Jv4Hcuhe62+JyJJKHGXRkZbFkCk0+D3OL4jp93DbQdgC0v9r3vqj/B6JlQ4VvmoHw2XPeAjNh56BMQ7IxPjnhZdod47ed+U/5f/H3IHw1PfEleFuoJa+GF78Kz3xAjdds/pP/Bz5zLobUWqt86ev4bnpZhpQWjj9yWWyyjkvJG9Xzs+Plgw7B/7dHz6Ik1j4ANwfzrjtw2egZ85gXIzJP+g2SyZQlkZMuw2xShxl1Jf5r3yWN9Io/IMy+SztEl3+vdGAIc2Ay7lsGJnzwytj/1/fChO2T6g8c/P3hj59sPitf+vg9KSARknvpL/9PNXf/bI48Jh+GZb8Abv4DKWyRc0pNhnnkRBLKOHpqp3wo1a6UhiIcJXqdqHCNmVj8or/6PndPz9twSCQf11Tj1l80vwpTTILsgueftB2rclfTH87YTeUTOzIFLfiTj3auO8sbk238CkwELevAUAeZ/FM75hsTvEx3eFytL75AOxXO+eXj63A9LmOSlH8oThUc4BE9+Ed68U+Lrl//s8JCGn9wSGce9/qneG6sNf5fvOZfFJ3/JZMgd1f9O1Zr1UsYLepv70FGxUIZpxhP26YmmPdKYpTAkA2rclZHA5hegcFzEa42X910J08+Tsd0tPSwbHArC2w/CzIuhaHzv5zntNnlkX/1QYvLEQlu9eO3HfQjGzzt8mzFiuE0AnvoXMc6hbnj0sxJaOuebcPEP+h5dNOdy6aCt3dDz9g1Pw7jjoXRqfNdgjHjv/R0OufohaWjnXXP0/SoWSuhm79vxyReN50ykaAikhxp3JT3Y9AJsXCxDHv2EQ1LZZlzQ/yGQ0RgDl/1EhgQ+/50jt29ZIgtsn9jHbNh5pdJB++5fY+ugPRoNO6Fpb+/bl/4vdDXL00JPlFTABd8R2Vf9SV5MWvMIXPjvcN63Yiuz2c4j7yk001IrYap4vXaP8fNh/7qjh8T8hENSvsde2PdsjBWV8p2s0MzmJVA4HsbNTc754kSNuzL86WyGB6+DBz4KP5slnYRbX5EKvmeVxJyTNSRtzEwZbbL6Adi5/PBtq/4kQx5nfaDv8yz4uHTQbno+flkadsKdZ8MvF8Bz3z7yFf22eomnH3fV0Q3NwlvEe33iC/De03DpT+S1/1gpngCTKsVDj2bjs9IZGm+83WP8fBltdGBjbPtvfw2adsOCa/vet2AMlE5LjnEPh2DrS9LxnKgzkSCxrMR0jzGmxq26FL3tX40x1hij66cqqWPLS7Lm6fn/Txa6fvdh+MOV8LM58Pd/BcyRozwS4eyvybjpv3814km2HpAhgQuug4ysvs9x7AXSEKx+MD4Zgp3iZYdDssD30v+VF4Le+GXkjdGlv4au1sgImd4IZMCVv4Ky6fCh/4VTb+2/PHMul4a0sfrw9A1PS8zce9M0Xib0803V1X+GnOLIU0VfVCyEXW8l3smdbGciAWLx3O8FLolONMZMBi4CBn9xQEXxs2kx5JTAmbfDR34HX9sMH71PRivUrJdRKvllycsvp1DGeu97V+YsAXjnL9LAnPCJ2M6RkSVjrzc+G9+kWM99G/ashKvugKsXwW1vwORTZf7zX50s89ksv1M6Tce+r+/zjX0ffGlV3yGl3phzhXy/90wkrbNFQmJzLk/cix09U14ki6VTtasV1j0u/QyxzP4JYtxb9om3nwibl5B0ZyJO+jTu1tpXgZ6077+BrwM6F6qSOqyV0MaM8yIec3a+eLPX/hG+vhU+MQALXR93FUw7x3Wu1kpIZtLJMO642M+x4DoIdcHaR/uX9zt/jbwp+r4PStq4uXKdNz4lMeanvypGrrdYe7IpnyUG2B933/KihFISDcmATEcwbm5snvv6p+Qlsr5GyfhJVtx9yxJZYD2ZzkScxBVzN8ZcCey21vY5lssYc6sxpsoYU1VbWxtPdorSO/veEY+rtzh3dkHs3lt/ONS52gp//oQMfYvVa/cYPx/GzpURNrFSswGevF3W47zwu0dun3YWfOZF+Oi9cNVveh/fPRDMuVxeuffewN3wtAxhnHJGcs4/3o2Y6St08s5DUDKlf2uWjpsnTwbVVfHL135QGocUD4H06LdxN8bkA98G/i2W/a21i6y1ldbayvLywV1DUBkBbFos36moUOWzZc7xXcvFMHgrN8WKMXDC9bC7Cg5s6nv/zhb4y6fkyeSa3/ce2w8EJBxzQj8812Qw5wpZdWjT8zIKaOOzMirImwQsUSbMl5kcjzZlcdNemRRswbW9j83vicxsmHBCYp77lhel83gIxNshPs99BjANWG2M2Q5UACuNMUcZ2KsoA8Sm52HiSVA4NjX5n/N18RKP9vr80Tj+ozLOvK+OVWvFY6/bJPOwFE+IT96BZNLJ8j7BhqdlbpWOhuSEZDximf539QNiYHuabqAvKiphz9tHDqeNhXAYXvtvGHWMjBwaAvTbuFtr37XWjrXWTrXWTgWqgZOstfuSLp2iHI22evG0Zl6cOhlyiuDzy2Qa2XgoGi9j8Ff/+ejzxb91F6x5GM77Nkw/J768BppAQDz1zS/IWPnM3OR2LI49ThrC3jpVu9vlha3p58GYfszZ71GxUPoI4pmBcs3DsP9duODfkvekkiCxDIV8EFgKzDbGVBtjbhl4sRQlBjYvES8tlcYdJK4fy/DH3lhwnUyHu72XmQm9RSxmXgzv/5f48xkM5lwhUyuv/KMY9mTOrZKdD2Nm9e65r/yDTGJ29tfiO7830Vt/QzPBTnjx+/JkMffq+PIeAGIZLXO9tXaCtTbLWlthrb07avtUa+2BgRNRUXph03MyVnziiamWJDHmXC5jsqNDM9bCqz+Bx26DY86UcEx/4sipYNrZskiJDSU3JOMxfn7PnnuwS8b4TzkDpp4Z37lLJkHRxP4b96p7pB/gon8fUvdn6EiiKP0hHJLH/5kXDakKFRdZeTJ0c90T0mkK8nLUU1+RoZbzr5W5zuOdrngw8eZ4j567PVlMmA/Ne+SlMT+rH5Qx6mf/a2Lnn7ywf8a9o1EW9J5+7pAY2+5nmNcKZcSye4UMPZt5UaolSQ4LPi7DKtc/KePT//xJWPF7eP9X4MN3ymiO4cKF/y5z1xcMwIvrPXWqhoLw+s/lCS5RA1uxEBp29DwxXE/841fQXt/zsNQUo8ZdGZ5sfE5m/Bti3lLcTDlNZk2suhvu+6CEnC77qRiNFM9R0m9Kj5GO1YHAm9nTH5pZ84hMWXz21xIvq0Nx9xjGuzfvk2kf5n1kSIYG1bgrw5NNi+V1+7zSVEuSHIyRNyqr35IVh679E5zy2VRLNfTIL5O5ajzPPRyG134mL4PNSkKDMmGBLMcYS2jmlf+UN4zP/7+J5zsAqHFXhh9Ne6Vyp0tIxuPkm2S0yY1PDkxnZLrg71Td8CQceA/O+pfk9L1k5cnTQV/G/cBmWHEfVH5aJlwbgqhxV4Yfm900ubFMrTucKBoP190Pk09JtSRDmwnzoW6zdD6/+lMomyFv5CaLioWwe+XRF/1+8Xsyjj/eYZeDgBp3ZfixabFMuTu2H5N0KenD+PmAlfVd973jvPaM5J2/YqF0btes73l7dZXMOnnGF1P3ZnQMqHFXhhfBLtjyshtuN8w6GpXk4M3t/trPJf4+P4YFOfrD0WaIrN8Gj9wCBeVwxheSm2+SUeOuDC92LpVl42amWUhGiZ3iSZBXJi9Kvf/Lib0d3BOl0yB/9JEjZvavhXsukbHt1/9Zpp4YwqhxV4YXmxbL4tLTzk61JEqqMAYmnSTrlJ4Q5+IifZ2/Iuplpl1vwu8vlZezbn4WKk5Ofr5JZmjMcKMosbJpsbyKn1OYakmUVPLB/5FJvrJyB+b8FZUyZXF7g7ww9+dPSof3DY/JOP5hgBp3ZfhQXSULJFd+OtWSKKmmZNLAnt97mWnJ92RCsvI5cMOjQ7oDNRoNyyjDg642+NvnoLgCTvh4qqVR0p2JJwFG3hiedDLc9NSwMuygnrsyXHjhuzK2+VNPQG5JqqVR0p3cYpn4LCMTPrxIphseZqhxV4Y+W16CN++EU28bugtVKOnHxx9KtQQJoWEZZWjT3gCPf14WabjwO6mWRlGGDbGsxHSPMabGGLPGl/YTY8wGY8w7xpi/GWPiWDxSUWLgmW/I7Hsf/q3M+6EoSkzE4rnfC0TPuv88MM9aOx/YCHwryXIpirzi/c5DMn/HpKE/rlhRhhKxLLP3KlAflbbYWht0f5cBFQMgmzKSad4PT34ZJpyQ+Oo6ijICSUbM/dPAM71tNMbcaoypMsZU1dbWJiE7Je2xFp68Hbrb4OpFyX+9XFFGAAkZd2PMt4EgcH9v+1hrF1lrK621leXl5Ylkp4wUNjwNG5+RVYjKZ6daGkUZlsQ9FNIYcyNwBXCBtdYmTyRlxLP6QSgcB6fcmmpJFGXYEpfnboy5BPgGcKW1ti25Iikjmo5G2PS8LL6QzDm6FWWEEctQyAeBpcBsY0y1MeYW4NdAEfC8MeZtY8xvB1hOZaSw4WmZEGreNamWRFGGNX2GZay11/eQfPcAyKIospL9qCmRBRMURYkLfUNVGTq01slUA/M+oqssKUqCqHFXhg7rHpPVdeZ9JNWSKMqwR427MnRY86jMITNuXqolUZRhjxp3ZWjQtAd2vCEdqRqSUZSEUeOuDA3W/g2wMO/qVEuiKGmBGndlaLDmERg/H8bMTLUkipIWqHFXUk/9VlmE+Hgd264oyUKNu5J61jwq33M1JKMoyUKNu5J61jwKk0+DUZNTLYmipA1q3JXUUrMeatbq2HZFSTJq3JXUsuYRMAGYe1WqJVGUtEKNu5I6rBXjPu1sKBybamkUJa1Q466kjj2rZKSMhmQUJemocVdSx5pHIJAFc65ItSSKknaocVdSQzgsb6UeeyHkl6VaGkVJO2JZrOMeY0yNMWaNL63MGPO8MWaT+y4dWDGVtGPnUmjarS8uKcoAEYvnfi9wSVTaN4El1tqZwBL3X1FiZ83DkJkHs6JVS1GUZNCncbfWvgrURyV/CLjP/b4P0HFsSuyEumHtYzD7UsgpTLU0ipKWxBtzH2et3QvgvnUcmxI7W1+G9noNySjKADLgHarGmFuNMVXGmKra2tqBzk4ZDqx5BHJLpDNVUZQBIV7jvt8YMwHAfdf0tqO1dpG1ttJaW1leXh5ndkra0N0O65+C930QMnNSLY2ipC3xGvcngBvd7xuBx5MjjpL2bFoMXc2y4pKiKANGLEMhHwSWArONMdXGmFuAHwMXGWM2ARe5/4rSN+8+DAVjZcoBRVEGjMy+drDWXt/LpguSLIuS7nQ0wcbn4OQbIZCRamkUJa3RN1SVwWPD0xDq1JCMogwCatyVwWPNI1AyBSafkmpJFCXtUeOuDA6tdbD1JZh3NRiTamkUJe1R464MDuseg3BQX1xSlEFCjbsyOKx5BMbMhnHzUi2JoowI1LgrA0/jbtjxD/HaNSSjKIOCGndl4Fn7KGB1xSVFGUT6HOeuKP0mHJIl9DY9D5ufh90rYdLJMHpGqiVTlBGDGncleWxeAqsflO/2esBARSWc+y048ZOplk5RRhRq3JXkUL8N7r8G8spg5sUw8yKYcb4uoacoKUKNu5Ic3lwEJgD/9DoUT0i1NIoy4tEOVSVxOppg5R9h7tVq2BVliKDGXUmctx+QaXxPuy3VkiiK4lDjriRGOATLfwuTT4VJJ6VaGkVRHGrclcTYtBgOblOvXVGGGGrclcRYdgcUV8CcD6ZaEkVRfCRk3I0xXzHGrDXGrDHGPGiMyU2WYMowYN8a2PYqnPJZyNCBV4oylIjbuBtjJgFfAiqttfOADOC6ZAmmDAOW/xay8uGkT6VaEkVRokg0LJMJ5BljMoF8YE/iIinDgtYD8M5fYMH1+qKSogxB4jbu1trdwE+BncBeoNFauzh6P2PMrcaYKmNMVW1tbfySKkOLqt/Lknmn/lOqJVEUpQcSCcuUAh8CpgETgQJjzBETiFhrF1lrK621leXl5fFLqgwdgl3w1u/g2AuhfFaqpVEUpQcSCctcCGyz1tZaa7uBR4EzkiOWMqRZ9xi07Nfhj4oyhEnEuO8ETjPG5BtjDHABsD45YilDFmtl+OOYWTDjglRLoyhKLyQSc18OPAysBN5151qUJLmUocrG52Su9lM/p6sqKcoQJqHBydba7wDfSZIsylCnoxGe+gqMPQ5O1OGPijKU0TdPlNh5/t+gZR9c9yfIzE61NIqiHAWdfkCJja0vw4p74fQvyJJ5iqIMadS4K33T2QJPfAnKZsB5/yfV0iiKEgMallH65sXvQ8NOuPkZyMpLtTSKosSAeu7K0dm5DJbfKZODHXN6qqVRFCVG1LgrvdPdDo9/HkomwwU6KEpRhhMallF65+UfQ91muOExyClMtTSKovQD9dyVntn7DvzjV3DiDTDjvFRLoyhKP1HjrvRM1d2QmQsX/yDVkiiKEgdq3JUjCQVh/ZMw6wOQNyrV0iiKEgdq3JUj2fE6tNXB3KtSLYmiKHGixl05krWPyfJ5x16UakkURYkTNe7K4fhDMtn5qZZGUZQ4UeOuHM6ON6DtABynIRlFGc6ocVcOZ50Lycy8ONWSKIqSAGrclQjhkIRkZl6sIRlFGeYkZNyNMaOMMQ8bYzYYY9YbY3TykeHMjjegtVZHyShKGpDo9AO/BJ611l5jjMkG1N0bzqx7HDLzNCSjKGlA3MbdGFMMnA3cBGCt7QK6kiOWMuiEQ7DuCZh1MWQXpFoaRVESJJGwzHSgFvi9MWaVMeYuY8wRVsEYc6sxpsoYU1VbW5tAdsqAsnMptNboKBlFSRMSMe6ZwEnAb6y1JwKtwDejd7LWLrLWVlprK8vLyxPIThlQ1j4mIZlZH0i1JIqiJIFEjHs1UG2tXe7+P4wYe2W4EQ7B+idg5kUaklGUNCFu426t3QfsMsbMdkkXAOuSIpUyuOxcBi37dZSMoqQRiY6W+SJwvxspsxW4OXGRlEFn3WMyve9MDckoSrqQkHG31r4NVCZJFiUVhMMySmbmRbrakqKkEfqG6khn1zJo2aejZBQlzdA1VEcqXW2w9m+w9NcSkpl1SaolUhQliahxH2nsXwcrfg+r/wydjTBmFlz1Gw3JKEqaocZ9pPDes/D6z2HXcsjIhuM+BCffDMecAcakWjpFUZKMGveRwIp74cnboWy6LHi94ONQMDrVUimKMoCocU933roLnv6qLJl37Z8gKzfVEimKMgjoaJl0ZvmdYthnXQrX3a+GXVFGEGrc05V//Bqe+TrMuQI+9gfIzEm1RIqiDCJq3NOR1/8bFn9bOk0/ei9kZqdaIkVRBhmNuacbr/0MlnwP5n0EPrwIMvQWK8pIRD33dKKjEZZ8H953pRp2RRnhqHFPJxp2ARbmXa2GXVFGOGrc04nGavkumZxaORRFSTlq3NOJxl3yXTwptXIoipJy1LinE027IZAFheNSLYmiKClGjXs60VgNxRMgoLdVUUY6CVsBY0yGMWaVMeapZAikJEDjbo23K4oCJMdzvx1Yn4TzKInSWA0lFamWQlGUIUBCxt0YUwFcDtyVHHGUuAmHoHmPdqYqigIk7rn/Avg6EO5tB2PMrcaYKmNMVW1tbYLZKb3Ssh/CQfXcFUUBEjDuxpgrgBpr7Yqj7WetXWStrbTWVpaXl8ebndIXjbvlW427oigk5rmfCVxpjNkOPAScb4z5U1KkUvqPN8ZdjbuiKCRg3K2137LWVlhrpwLXAS9aaz+ZNMmU/tHkPHeNuSuKgo5zTx8aqyG7CHJLUi2JoihDgKTMLmWtfRl4ORnnUuKksRpKJuli14qiAOq5pw86xl1RFB9q3NOFpt0ab1cU5RBq3NOB7nZordWpBxRFOYQa93SgaY98a1hGURSHGvd04NAiHRqWURRFUOOeDhwy7uq5K4oiqHFPB/QFJkVRolDjng407oKCsZCZk2pJFEUZIqhxTwcad2u8XVGUw1Djng7oC0yKokShxn24Y617gUmNu6IoEdS4D3c6GqCrRT13RVEOQ437cOfQIh0ac1cUJYIa9+HOoTHuOvWAoigR1LgPd5r0BSZFUY5Ejftwp7EaAlkyzl1RFMWRyALZk40xLxlj1htj1hpjbk+mYEqMNO6G4okQ0HZaUZQIiazEFAS+aq1daYwpAlYYY5631q5LkmxKLOgYd0VReiCRBbL3WmtXut/NwHpAh2wMNk1q3BVFOZKkPMsbY6YCJwLLe9h2qzGmyhhTVVtbm4zsFI9wSOZy1wnDFEWJImHjbowpBB4BvmytbYrebq1dZK2ttNZWlpeXJ5qd4qdlP4SD6rkrinIECRl3Y0wWYtjvt9Y+mhyRlJg59AKTGndFUQ4nkdEyBrgbWG+t/XnyRFJipnGXfKtxVxQlikQ89zOBG4DzjTFvu89lSZJLiYUm9dwVRemZuIdCWmtfB0wSZVH6S2M1ZBdBbkmqJVEUZYihb74MZ3SMu6IovaDGfTjTWK2zQSqK0iNq3IczTbvVc1cUpUfUuA9XujugtVZXYFIUpUfUuA9XdKSMoihHQY37cOXQIh0ac1cU5UjUuA9X1HNXFOUoqHEfrnieu04apihKD6hxH640VsvqS5k5qZZEUZQhiBr34Yq+wKQoylFQ4z5cadqtnamKovSKGvfhiLXOc5+cakkUZdjT2N5NOGxTLUbSSWQN1ZQTCnTwn08AABnjSURBVAYJh0NkZac27mzDYfZXb6Fmy2ra9qzF1G8FEyCcXYjJLoKcQjLyisnMKyJvdAUTps2jZPS4+DPsaICuFu1MVZQ4aO0M8ua2el7bdIDXN9eycX8LowuyOWvmGM6ZXc5ZM8sZUzj8+7KGhXFfet+3GbfjKbJsFzm2gxw6ybVd5JhuQjaDlYVnYBZcx9xzriE7JzcpedpwmI72VpobDtDaUENbwwE6m2sJttQTaq3DtB8ks62GkrbtTOreyXjTyXh3bCMFAOTbDrJMqMfzN1DI/swKmgqmEBw1ncyyY8guGkNu8RgKy8ZRWDqO4pIyTCBAS9NBDu7fSVNNNe0Hd5NZu54TgGX1eYza18SM8kKyMob+Q1hnMERjWzcN7d00tHVzsK2L9q4QxkDAGPcB475zsjLIzQyQk5VBTmaA3KwM8rMzGFuUgywnkHw6ukPUNndSUZo3YHkMJG1dQWqaOtnf1EFTRxBrLRZ52BMsXSHLwdYu6lo6qWvtoq6li7rWThrausnNyqAoN5PCnEyKcrMoys089L8g5/DfhTmZdHSHqD7YTvXBNvctv9u7Q0wbU8D08kKmjylgxthCZowpZMKoXJo7gtS3dnKgpYt6J0dTR5CZYws5ddpoSvKz+rzOju4Qda1dBENhukNhukOWYMjSHQ7THQzTEQzT0R2ioztEZ3eYjmCIupYulm6tY9XOg3SHLDmZAU6ZVsYV8yey7UArr26s5bG39wAwb1Ix58wqZ0JJ3qHztHeHaO8K094dIjNgGFuUw7jiXMYWu++iHErzswkEhobeGGsH73GksrLSVlVV9fu45X/5L7K3v0QoI49wRg42M49wVh5k5RNoq2Pmgecpo4mDFPNe+QcYfeaNHDv/TExADF4oGKSxfj9NdXtpqd9LZ+MBgi0HCLeJkc7oaCCrq4HcYBN5oWYKws0U2xayTbBXmTpsFg2mhNqcybQWH4spn03R5HmMnzGfsrHiUdtwmM7OdtqaG2hvaaKj5SDN+7fTsX8j5uBWCpu3M6armnHU9ZhH0AboIot803nEtgZbwJVdP2CnHUd2ZoDZ44o4bkIxx00sZnp5AVPK8pk4Km/AjX5nMMTuQ5W6nQMtndS3dnGwrevQ98FWMeRtXT03dP1lQkkuZ88s55zZ5Zx57BhK8g43Bo3t3azYUc/yrfUs31ZPS2eQitI8JpfmM7ksj4rSfCaX5pOXHWDj/hbe29fMe/ua2bi/me11rYQtTC7L47J5E7j0+AksqCgZUEPf1hVkV307O+vb2NPQTlN7N82dQZo7gjR3dNPSGaSlQ3QxI2DIzDBkBAJkBQwZAUNLZ5D9TR3UNHfS3NG7zkZjDJTlZ1NWkM3owmxG5WXTGQzR3BGkxeXf5PKPxUyMKcyhojSPitI8cjIz2F7XypbaFhrauvsl09yJxZw+fTSnzxjNwqllhMKWdXuaWLuniXV7m1i7p5Etta2E4gilzJ1YzPtnjuGsY8upnFpKblbGoW3hsGXtniZe3VTLK+/VsmLnwcPyyAgY8rMyyM3OoDsU7vG6sjMCjCvJYUJxHhNG5TK+JJeJJXlMKMnl5GNKGR3nE4ExZoW1trJfxwwH494X3V2drH3tb4RXPcC85jfINkF2mYkETRbF4QZG2SYyTM/X2WZzaDLFtGYU0Z5ZTFdWMcHsEkI5JZA7ikB+GZkFZeQUjyavZCyFpeUUl44lr6AoafK3tTRSt28nrQ01dDbV0tVUR6j1ALatHhPshMKxZJZMILdsEkVjKhg1bgoFRaVsq2tzyt7klL+Rgz6FCxiYOCqPKWX5TCnLFyPovGSD+3b/szyDkWHIDBgyMgIEDLR3RXstQVo6Q+xpEA9tf9ORDU9RbiZlBdmUOsNRmp/NqPwsSvOzKMnPpjQ/i1F5kpafneE8S4u1ELYQtpZQ2NIZDNPZHaLTeWGdwTCN7d0s21rH65sP0NwRJCNgOGHyKM6aOYbG9m7e3FbPur1NWCsVbcHkEsoKsg81Po3tR1ZIY2Dq6AJmjyti1vgiRhdk89J7Nby+6QDBsGXSqDwuO348l8ybwNTR+eRnZ5KbFYjZ4Ld2Btnd0C6NoPd9sI1dB9uprm+jrrXriGNyMgNHeM7GQDAkZRMMW4LhMMGQJT87g/EluYwtcl5kUS7jinMpycvCE9EYMG75hawMQ6m7LxkxeJnhsKW9OySNjGtoWjuDNHcGyckMMLksn0mj8g4zlH7qW7vYUtvC1toW9jZ2UJKXxejCHEa7RqWsIJvCnEzerW5k6dY6lm6pY9XOBrpCYQJGdMJjfHEucyeKE1NRKs5LZoY0dJkZATIzDNkZAXKzAuRkZpCblUFuljz1FWRnkpfds4w90dIZpK0zSG52BnlZGUc4St5TXk1zB/ubOqlp6mBvUwf7GjvY29jB3sZ29jV20B2SC7j35oWcO3tszPn7GXTjboy5BPglkAHcZa398dH2Hyjj7qexvpYNS+4jd+tzhAPZdOWOxuaNwRSWk1k8lpySsRSMGkth6TiKSsvJzSsYUHkGE2st+5s62V7Xys76NnbVt7HT+9S1iQdGxJBaxJDGogJ+ryU/O4MJJbmHPOCK0jyp4KV5lBfmkJ058CGiYCjM27saeGVjLa9srOXd3Y1kZwQ4aUopp04v49RpozlxyqgjDE5je7cY1vp22rqCzBxbxMxxhT0apsa2bhav28cza/bx2qbaQ5UUxFgWZGeSn51BQU4mAcOh8Ie1lrAFi6W5I3iEh5eVYZhQIo3uoSeJsnwml+YxqTSPUXnZg1KGQ5mO7hArdxxk+bZ6crMymDuxmLkTi+P2fFNFOGypa+1iX2MHx4zJpzi375BTTwyqcTfGZAAbgYuAauAt4Hpr7brejhkM4670n3DYErKRmGXIfVsLuVnitQx1Y9PY3n3IWxuo87+2qZa6li5au4K0d4Vo7QzR1hWktStEOGzFOz70VCS/C3IymDRKGr5JoyRkUV6YM2TissrwIB7jnkiH6inAZmvtVpf5Q8CHgF6NuzI0CQQMAQxZGZDHwBjHgSY67j4Q579i/sQBzUNRkkki7tgkYJfvf7VLOwxjzK3GmCpjTFVtbW0C2SmKoiixkohx7+m58ogYj7V2kbW20lpbWV5enkB2iqIoSqwkYtyrAf8rkhXAnsTEURRFUZJBIsb9LWCmMWaaMSYbuA54IjliKYqiKIkQd4eqtTZojPkC8BwyFPIea+3apEmmKIqixE1C0w9Ya/8O/D1JsiiKoihJYmgPXlYURVHiQo27oihKGjKoc8sYY2qBHXEePgY40I/0eI5JVnq65z0YeYzUvAcjD817aOURC8dYa/s3llzmGRn6H6CqP+nxHJOs9HTPO92vT8tW8x7MPAbqo2EZRVGUNESNu6IoShoynIz7on6mx3NMstLTPe/ByGOk5j0YeWjeQyuPAWFQO1QVRVGUwWE4ee6KoihKjKhxVxRFSUcGYggOcA9QA6zxpS0AlgL1QCewzqVnA48B3ciUwW1Asdv2CSDs0sPAZS79ZHcO6z6PI1MQf8a3vz/9ZHdeLz0IHOPyfs+XHgYW9pC3BZa5a9ofld7tztcErHTbwr59QsCLQDvQFZW+GNjrzhFy2zuB191vb78O9/t1dx5P1v3ud21UeYTc94qo6wsB64F3nKz+6/bK9ue+dAvc5NJ/FHXdn/Pdi9aoYx53ZdXtS2sHml1ZdfquqdMnbxjRD385ed/17nwdwFa3TwhZDazb7Rf0ldubvvw7kPcrvPz8525xv9f75LDIeOS1yOyn/mv7i7vuM11+0TpVAjRGle1CIB94jZ51qiYqD0+nmt11e/oUculhX1m0R5XfXmAfEZ1qdfsd9JVHCNFX69u3J53y37+gL+8G33UEXVmvJaKb3ueKXnTqRWQ+qh9Fpb/i0qPrt0UmJayJukfdRHTKKy9PD/xl0kqk/nlpIXeP63zHt7uyWurb19Nd69Jr3D6tvrLaC7wKvIvok5d3lc/+vYzYoLVI/fsOUgeDwDW+/f4FWfDoHWAJMr49Pjs8QMb9bOAkDjfubwHnuG3fBWpc+uedIn0RuMAV6vfdtk5gjTtXh7sRAXdTu4FVRIzEZUhFDBExECFX8M1unyYilbnL5W3djar33fibfMrjV/Dv+vap993EP/qUwZ/eTKRR8ad3Abf7FKfFl8caIpXmVSKVsT4q3atcB4kYw0/65D3gy7s5Ku/nfdfnb4ye8uV30CfTzU7GYFR6DZHK1eBLbwZ+TMSw+g3Bd3z7eZXMK1tPjlrf9tt9x9f59u/07dOFGHnvHnvn6UQqpLefZ+DCiK55BvCArzwO+MpwORH96iBizL3fXh5+nfqyTw6/Tt3qk7UnnQoixqInnfIbtWak4lu3f5Mv70m+66jz5bHaJ0e0ToVc+ru+MvV0KojUn4dc+k6fTI2IofLO9ZSv3Gt898yvU/6G9TdEdKrOl95IRKcO+sq8jcN1qsZ3Xr9O+fP+LhEd2x+V9z5feXr1pJNIY+6vfx0u3Ws4nvKVw0HfthsQnQkjetSA2JaDvrJuJVL/6py8re7zlJNzn/v9rtt+E/A7l+Z9XsU5XoM6zt1a+6q7GD+zgVfdtueAYpd+HFAI/BrYgijmJ4wxExDP+sfuXPXumErEwNcCHwa2I4X2GWAsYixfJOJ5tCBeU6u1thhZ89XDW5OwEGlAgu5/ifteAnyOyI0c5dLbrbVliFKEkaeSgFy6LSOiTB3uWIBLXHoIUeBHXfpm4BkiBvmnLn0X8FV3foO05haZM/9TLu8Q4pEGiDRsngJvIuJF3O3KotPJ7pXBUiJGLwR8zx37PHCi+w0wFcgDXvClhxEPOt+l3+u71u2AtybdXT5ZPY/HIorvpTe6su1C7t/l7tj1RLzgMPBpd03NiJeHO8czwI1unywiFf03wPUuj3bEGBlXVscRaXg2uXPdjHiIe93xL7iybUYqXIM71zvuPItdHl55hoCZ7tgSRKf8jSqIbn6OiNHydOpFa+04IoZmgsu701o71ldOtUSWsvwg0ggA7LHW7ibSgJzsvpuB/3b7NAE/Q+63p1MGMdr3E2kQPJ16FXGg3nDHP0fEQP8e+KH73WmtvcId24J4pF4j6unUjS6Pne5c5UR06mRXviD1xtOp+4D/49IPcLhOeQ1ZF4frlLcaXBsRnepwZQURR++g+/8fiFcdRnTKq5erkHrWjNihJa6s1rhrfZ1I/VsD7Aa+DdzhymgTUrfvdbJ8BdG737n6dwB40pXVr136FcCDwEPu96eIrJHRaq29wvsAX6IPBjPmvga40v2+DKmEIF5FK3AVsuBHHqLYk5AKeRvyqJaHzGI5GSmsfJde5r6nIK2cd95CIAdpENqALGNMJvBxtz2MFJwF7kRuViZyA0tdeiVywwMu3auIucaYd1y+Abd/ADDGmDfcseUu/1x3zGQiTx4gFRxgBmL4DVCFvKIMMN59cNsyEUUtd/lmu+8cRFFGuTw8WXPddXe7PIw7psAYc4q7/hnu/P6y7QaOd+f2VtsqQ5T8NFcexuWT69JPcuXvkYMYZlx55xG5hx7F7r91v0vdPvlIA4K7Vq+8AkhFKUL0xbhjc9x1XOaTyfPoZiA65ZUTvrKa5vLKdMeEEF3zZPMagRonZ7fvOprd53i3303uuCZEn8OITv3D7e8RRHRqJRFd83TqHKdTXnqj+87x6VQJYqhmu2MmE3mdvdUYM9+VQR7ScGe7sip0xxchdSufiE51uDJa5rtuT6dmIPfccziqiTztXI94kwGXD4i+FQLnEakbnk7dBlyMhK5AjLmnU+udXN45PJ26DmkccHJ6OvU5xDZ4Ou0xikgIJY/Dder3vv3PQhphEAfqXOSenUSkXo513znuOM9JGOvsyAwierUdqbfLXRn66/3pyP3u9IR09S8DaYyOxi2IXYqLwTTunwY+b4xZQUTZQOLzTyGt9N+JhEIMUlEqkIahgMMfl3JcegkRz+6rSKFdhdxQzzt61aU3AR9z+XYiLWcQUaJi5Obh8g4jCrWGSAX1Yp1dwLFIxQFRBO96CpBYdwCpTF5jE0Raf4sowjUu/QDSQltE+T+ONALZwMNEjJhFlDvTyZRJxEv/sdv/Bz5ZvSeBrcAH3HbPs/8j4oUVEWkovEfOLS59ne88YcSjDRBRek+mJxDjfymRKaQt8BeXX5Y7zmvYvszhrHDX+AknSzdwhvvOB37rjrPA15GKVAqc6o5vQoydVym9sNF+d91/910DvrLywieeZ92A6NoNRJ4q24nc7xmIwfBiuE+4cvpnIsZ9L6LPjYhOlRN58jJEnp5W+MrP87T3ITrl1cmzffsUIkYPYA7SMOGOvdaV7Wx3Xu98p7uyKQV+QiR880tXzt6525H7/gyRhtHTqRL38RqQY4jEmktdmgWse9L2npA8w+7V1y2ubCcQqSeTiOgURJ6aC4noVAniEePK3tOpDuQJoYvDdSqM6K33ZOLXqSokvJTpytAztr9E6p9XD3YjUYIJSH3zyuoRl17iytK7txapYwa4EHlC8cJbeUiDs4UI+Uj9W8xRMMZ8EnEE7jvafkdj0Iy7tXaDtfZia+3JyM3rculBa+1NLmQyHymw7YiXUGqtPQZ4H5GOj03IDdjh0ne4Y7YhRrwJ6aCtdfs3uv2bkCcHL4ba5h0blTduWwaReKCHZ1B3WGvzEQ8ARKGC7lwnWGvPINKJ5cVjNyHhmyZ3bd5TzGoiMbs2xMPIQB7p3k/EAHlGaL277nZ3TLs7fiOiWF4812t4nifyqGgRJfy/bv97iHSuhZyMne6YXb689yOKfY/L2ztPm7u+breP5+lPRcIe3dZaz9Pe6Y77hVeGSIjIM+QPEOlQPsWV5+NIrBonxzYiTyMr3D7vIY+y1xJpnL1yvQO5r54Rw5VVG9K56XVmtwIhp2vbvP9IY/J1xENtdrJ1IQ2BVx67fWXbaq0Numt9GPgTkXBMLoc/SULEew67vB9CDBiIHoRcvisQg9CCxGFfcPndgBjBr7ry/407dpv77kZ0aTny1FODhLy865uO3PvfIvfVW8He06k/I07AT1x+3tOZV7a3EHEKnkbCN79D6p+nf55O3eKuZZs7ZjyH65Qncz6H61S+S5+AT6estaOQ+wc+nbLWzicSzozWqV8hnb+vEOmTm40YfuvK+Qkn1xYOr2edyJP+Jlf33yRS/44l0jgcg9zn6UhDNRZxbH+FNGg3IfXPC0P1xGQkxHOlK4e4GDTjbowZ674DwBdwMXljTL4xZqrb7SzE0/uFtXYv0GmMORepBOVIJ+w6pCBbkcf3iciNuQ8p3G5E4UuJjA7xWt97iSjwXlw81xhzmi/vDkSp2pAb4RnwDiTWCvIIfDrSmntKEQBCxpjTjDGfQ27wPiLe3jykFc90sv+vO9cmROlx+U9xx6xHPKYAUqFBbvoODn8c7XLHHIN4A5lEOm68pwfcMVnAVmvtX12652kXAi2ubIuQzsbPEjHge1w5eyEDQyTWmYPE9KcT8WRWuevyjH0G4vl6Fd64MsaVldeYZblr9sI1/tBQl9snl4g35m2rR3TKIkYbIiGgs4g8iWUgHn4R4u2Ncce2iijmP50MXrksQirxma4sA0T6f4oQT20i0lAGEb3IR+5TCfAScp/aECNQjzy9LSDyBPCOL29/nL7Gl2cJ4kDkIM7GaU6+AnfeS5zMT7tr/YfbXuj+34cYxjBitAqRe5rh/nv31Xti8Z5ML0P07dMufa2Tx9vP62sKIQ1Tg6/s8hFDvM7tfzfSKI1zcmxG9NYLBU126Y3uuh5EdMrzenchDWkAKbBLXNl3EAmd7Hchk8+7/55OHUT0oRGpJ3uJhE2WIjF/78lqCmI/9jk58pH6Z5AGptHZMC+k2YUMFmlDGopFLm0ZYmvuQhqwL7vzL3X1rzfKkfp3pbW25ij79c0AjZZ5kIhXVI202rcjlcAbseJt+zqRUQJez7Z3zCIij4nWnfMWV3D+IWXdLv13UfuHES90WVS655F+Peo8nod3N5ERFP7923o4v3/Ehz8t+pxNRLwAT+YGeh5ydrCHc9iofKxvn5727e0TRjzL7h623ULkycb/WUmkk9F/npoe7oW3rYkjZfc/gURfg/fxOlV7Omd0OfvLpLcyiKeMvE8dkREv/s9aDh9K6s/rhz2kdxEZcRK9f286Fe4hradrb4lK94YERutUdLn3pqu93Ze+Prt7ube3cOSwRq9Ddn9Ueocr2xU9nN97ivGndRLpA4gug+hjmzi8TnsO0MGo/YOInTqa/nkjpJp85wojDtnmHvL+G9JpapH6/jaiV16j3wTUOdu508n1tvu8jDiZv4iysSfQx2iZQZt+MsmNR/SF/uJo27xPVMEsdr9XRe1/vyvM/qb3mEesebv9jjiX+33C0dL91410Dl3Vw/Wfi/RF/KKP9FVR8ibl+pJctvd7eUdd+/3+8uhPWUXtey7w5NHK0P9JF52KLsOo8ohZp3xl+6Rfpuj7lOj1DXWdirP+9XTtN/nT/OnRttH/GZZzyxhjXufwSe/HWGvf39s2ZPjZ54nEPw1Qb609zhizk0inJ8gj3s1IjKw/6Sf3lAcSe40l79HueyUSvilHQgxnId7J9qOk7/PKwBizEHk5xAuBnIV4BjuQR/MM3/E9pV+MeBhNSb6+ZJbtaMTL24OELLKd7GcjXtc+pNOsP2V1FpFhczuQkIM33LKnsqpFwgbdbls66BRRZQhSf75C/3RqtTuvV4YXEwnfNCXx+mIpw1TqVCxlFZ0+x8m42h2fjYy8OhnpP8Kfbq19nF4YlsZdURRFOTo6t4yiKEoaosZdURQlDVHjriiKkoaocVcURUlD1LgriqKkIf8foJNNNrBgW30AAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(((valid-norm_min)/(norm_max-norm_min)).values)\n",
    "plt.plot(((valid-norm_min)/(norm_max-norm_min))[:50])\n",
    "plt.plot(predict_res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f43a7358",
   "language": "python",
   "display_name": "PyCharm (JupyterProject)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}